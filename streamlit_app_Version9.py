import streamlit as st
from docx import Document
import re
import os
import html

LAWS_DIR = "laws"

# Ø¯Ø§Ù„Ø© Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø±Ù†
def normalize_arabic_text(text):
    text = re.sub(r'(.)\1{2,}', r'\1', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø¯
    text = re.sub(r'[\u064B-\u0652]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = re.sub('[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)
    text = re.sub('[Ù‰ÙŠ]', 'ÙŠ', text)
    text = re.sub('[Ø©]', 'Ù‡', text)
    text = re.sub('Ø¤', 'Ùˆ', text)
    text = re.sub('Ø¦', 'ÙŠ', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub('\s+', ' ', text)
    return text.strip()

# ØªÙ…ÙŠÙŠØ² Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
def highlight_keywords(text, keywords, normalized_keywords=None, exact_match=False):
    for kw in keywords:
        if not kw: continue
        pattern = re.compile(r"(?<!\w)"+re.escape(kw)+r"(?!\w)", re.IGNORECASE)
        text = pattern.sub(r'<mark>\g<0></mark>', text)
    if exact_match and normalized_keywords:
        normalized_text = normalize_arabic_text(text)
        for i, norm_kw in enumerate(normalized_keywords):
            if not norm_kw: continue
            original_kw = keywords[i]
            if norm_kw in normalized_arabic_text(text) and not re.search(r"(?<!\w)"+re.escape(original_kw)+r"(?!\w)", text):
                pattern = re.compile(norm_kw, re.IGNORECASE)
                def replacer(m):
                    return f'<mark class="mark-soft">{m.group(0)}</mark>'
                text = pattern.sub(replacer, text)
    return text

# Ø­Ø¬Ù… Ø®Ø· Ø§Ù„Ù†ØªØ§Ø¦Ø¬: Ø§ÙØªØ±Ø§Ø¶ÙŠ 18ØŒ Ø£Ù‚ØµÙ‰ 20ØŒ Ø£Ø¯Ù†Ù‰ 18
if "results_font_size" not in st.session_state:
    st.session_state.results_font_size = 18

# ------------------ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª ------------------
tabs = st.tabs(["ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†", "ğŸ“„ Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ÙƒØ§Ù…Ù„"])

# ------------------ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¨Ø­Ø« ------------------
with tabs[0]:
    st.markdown("""
    <style>
    mark {
        background: #ffd600 !important;
        color: #000 !important;
    }
    mark.mark-soft {
        background: #ffe082 !important;
        color: #000 !important;
    }
    .result-box-custom {
        background-color: #f1f8e9;
        color: #232323;
        padding: 20px;
        margin-bottom: 10px;
        width: 100%;
        max-width: 100%;
        border-radius: 10px;
        border: 1px solid #c5e1a5;
        direction: rtl;
        text-align: right;
        font-size: %dpx;
        transition: font-size 0.2s;
    }
    </style>
    """ % st.session_state.results_font_size, unsafe_allow_html=True)

    # Ø£Ø²Ø±Ø§Ø± ØªÙƒØ¨ÙŠØ± ÙˆØªØµØºÙŠØ± Ø­Ø¬Ù… Ø®Ø· Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬)
    st.write("### Ø­Ø¬Ù… Ø®Ø· Ù…ÙˆØ§Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    col1, col2, col3 = st.columns([1,2,1])
    with col1:
        if st.button("â–", key="decrease_font") and st.session_state.results_font_size > 18:
            st.session_state.results_font_size -= 1
    with col2:
        st.markdown(f"<div style='text-align:center;font-size:18px;'>{st.session_state.results_font_size}px</div>", unsafe_allow_html=True)
    with col3:
        if st.button("â•", key="increase_font") and st.session_state.results_font_size < 20:
            st.session_state.results_font_size += 1

    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†
    if not os.path.exists(LAWS_DIR):
        st.error(f"âš ï¸ Ù…Ø¬Ù„Ø¯ '{LAWS_DIR}/' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†.")
    else:
        files = [f for f in os.listdir(LAWS_DIR) if f.endswith(".docx")]
        if not files:
            st.warning(f"ğŸ“‚ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ù‚ÙˆØ§Ù†ÙŠÙ† ÙÙŠ Ù…Ø¬Ù„Ø¯ '{LAWS_DIR}/'.")
        else:
            with st.form("main_search_form"):
                selected_file_form = st.selectbox("Ø§Ø®ØªØ± Ù‚Ø§Ù†ÙˆÙ†Ù‹Ø§ Ù„Ù„Ø¨Ø­Ø«:", ["Ø§Ù„ÙƒÙ„"] + files)
                keywords_form = st.text_area("ğŸ“Œ Ø§ÙƒØªØ¨ ÙƒÙ„Ù…Ø© Ø£Ùˆ Ø¬Ù…Ù„Ø© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§:")
                article_number_input = st.text_input("Ø£Ùˆ Ø£Ø¨Ø­Ø« Ø¨Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø©:")
                exact_match = st.checkbox("ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù… Ù„Ù„ÙƒÙ„Ù…Ø© (Ù„Ø§ ØªØ¸Ù‡Ø± Ù…Ø´ØªÙ‚Ø§ØªÙ‡Ø§ Ù…Ø«Ù„ ØªØ¸Ù„Ù… Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¸Ù„Ù…)")
                submitted = st.form_submit_button("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø«")
            if submitted:
                results = []
                search_files = files if selected_file_form == "Ø§Ù„ÙƒÙ„" else [selected_file_form]
                kw_list = [k.strip() for k in keywords_form.split(",") if k.strip()] if keywords_form else []
                search_by_article = bool(article_number_input.strip())
                normalized_kw_list = [normalize_arabic_text(kw) for kw in kw_list] if kw_list else []
                norm_article = article_number_input.strip()
                for file in search_files:
                    doc = Document(os.path.join(LAWS_DIR, file))
                    law_name = file.replace(".docx", "")
                    last_article = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"
                    current_article_paragraphs = []
                    for para in doc.paragraphs:
                        txt = para.text.strip()
                        if not txt:
                            continue
                        match = re.match(r"Ù…Ø§Ø¯Ø©\s*[\(]?\s*(\d+)[\)]?", txt)
                        if match:
                            if current_article_paragraphs:
                                full_text = "\n".join(current_article_paragraphs)
                                add_result = False
                                simple_full_text = normalize_arabic_text(full_text)
                                if search_by_article and last_article == norm_article:
                                    add_result = True
                                elif normalized_kw_list:
                                    for idx, kw in enumerate(normalized_kw_list):
                                        if not kw:
                                            continue
                                        if exact_match:
                                            pattern = r'(?<!\w)'+re.escape(kw)+r'(?!\w)'
                                            if re.search(pattern, simple_full_text):
                                                add_result = True
                                                break
                                        else:
                                            if kw in simple_full_text:
                                                add_result = True
                                                break
                                if add_result:
                                    highlighted = highlight_keywords(full_text, kw_list, normalized_keywords=normalized_kw_list, exact_match=exact_match) if kw_list else full_text
                                    results.append({
                                        "law": law_name,
                                        "num": last_article,
                                        "text": highlighted,
                                        "plain": full_text
                                    })
                                current_article_paragraphs = []
                            last_article = match.group(1)
                        current_article_paragraphs.append(txt)
                    if current_article_paragraphs:
                        full_text = "\n".join(current_article_paragraphs)
                        add_result = False
                        simple_full_text = normalize_arabic_text(full_text)
                        if search_by_article and last_article == norm_article:
                            add_result = True
                        elif normalized_kw_list:
                            for idx, kw in enumerate(normalized_kw_list):
                                if not kw:
                                    continue
                                if exact_match:
                                    pattern = r'(?<!\w)'+re.escape(kw)+r'(?!\w)'
                                    if re.search(pattern, simple_full_text):
                                        add_result = True
                                        break
                                else:
                                    if kw in simple_full_text:
                                        add_result = True
                                        break
                        if add_result:
                            highlighted = highlight_keywords(full_text, kw_list, normalized_keywords=normalized_kw_list, exact_match=exact_match) if kw_list else full_text
                            results.append({
                                "law": law_name,
                                "num": last_article,
                                "text": highlighted,
                                "plain": full_text
                            })
                if results:
                    st.success(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results)} Ù†ØªÙŠØ¬Ø©.")
                    for i, r in enumerate(results):
                        with st.expander(f"ğŸ“š Ø§Ù„Ù…Ø§Ø¯Ø© ({r['num']}) Ù…Ù† Ù‚Ø§Ù†ÙˆÙ† {r['law']}", expanded=True):
                            st.markdown(f'''
                            <div class="result-box-custom">
                                <p style="line-height:1.8;margin-top:0px;">
                                    {r["text"]}
                                </p>
                            </div>
                            ''', unsafe_allow_html=True)
                            st.code(r["plain"], language="text")
                else:
                    st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„Ø¨Ø­Ø«.")

# ------------------ ØªØ¨ÙˆÙŠØ¨ Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ÙƒØ§Ù…Ù„ ------------------
with tabs[1]:
    st.markdown("<h3 style='text-align:center;'>Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ÙƒØ§Ù…Ù„</h3>", unsafe_allow_html=True)
    if not os.path.exists(LAWS_DIR):
        st.error(f"âš ï¸ Ù…Ø¬Ù„Ø¯ '{LAWS_DIR}/' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†.")
    else:
        files = [f for f in os.listdir(LAWS_DIR) if f.endswith(".docx")]
        if not files:
            st.warning(f"ğŸ“‚ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ù‚ÙˆØ§Ù†ÙŠÙ† ÙÙŠ Ù…Ø¬Ù„Ø¯ '{LAWS_DIR}/'.")
        else:
            law_sel = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†:", files, key="law_select_for_view")
            if law_sel:
                doc = Document(os.path.join(LAWS_DIR, law_sel))
                st.markdown(f"<h5 style='text-align:center;color:#1976d2'>{law_sel.replace('.docx','')}</h5>", unsafe_allow_html=True)
                law_text = ""
                for para in doc.paragraphs:
                    txt = para.text.strip()
                    if txt:
                        law_text += txt + "\n\n"
                st.text_area("Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† ÙƒØ§Ù…Ù„:", law_text, height=700, key="full_law_view_text", disabled=True)